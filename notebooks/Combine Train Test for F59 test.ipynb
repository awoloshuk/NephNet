{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules loaded\n",
      "Reload complete\n",
      "GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../NephNet\")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from data_loader import data_loaders as module_data\n",
    "from model import loss as module_loss\n",
    "from model import metric as module_metric\n",
    "from model import model as module_arch\n",
    "from data_loader import databases as module_datasets\n",
    "from base.base_data_loader import BaseDataLoader\n",
    "from trainer import Trainer\n",
    "from utils import Logger\n",
    "from utils import util\n",
    "from utils import tSNE_test as tSNE#import Identity, tSNE_generator\n",
    "from utils import torchsummary\n",
    "from utils import viewTraining\n",
    "from utils import lr_finder\n",
    "from utils import classActivationMap\n",
    "import importlib\n",
    "import math\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "import skimage.transform\n",
    "import jupyter\n",
    "from IPython import display\n",
    "from ipywidgets import *\n",
    "from utils import hyperband as HypOpt\n",
    "import argparse\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "from utils import transforms3d as t3d\n",
    "import pandas as pd\n",
    "\n",
    "import cleanlab\n",
    "from cleanlab import baseline_methods\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Modules loaded\")\n",
    "\n",
    "\n",
    "importlib.reload(module_data) #load recent changes to data_loaders.py\n",
    "importlib.reload(tSNE)\n",
    "importlib.reload(module_arch)\n",
    "importlib.reload(module_loss)\n",
    "importlib.reload(module_metric)\n",
    "importlib.reload(util)\n",
    "importlib.reload(viewTraining)\n",
    "importlib.reload(lr_finder)\n",
    "importlib.reload(classActivationMap)\n",
    "importlib.reload(HypOpt)\n",
    "print(\"Reload complete\")\n",
    "\n",
    "print(\"GPUs available: \" + str(torch.cuda.device_count()))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/config_pruned.json'\n",
    "\n",
    "# load config file\n",
    "with open(config_file) as handle:\n",
    "    config = json.load(handle)\n",
    "# setting path to save trained models and log files\n",
    "path = os.path.join(config['trainer']['save_dir'], config['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW FILE C:/Users/awoloshu/Desktop/datasets/f33f44combined_noCNT/3d_all/pruned_train_test/f33f44combined_noCNT_3d_all_prune_bad_labels1_combined.h5\n",
      "\n",
      "Successfully created C:/Users/awoloshu/Desktop/datasets/f33f44combined_noCNT/3d_all/pruned_train_test/f33f44combined_noCNT_3d_all_prune_bad_labels1_combined.h5\n",
      "===============\n",
      "6 keys in this file: ['/Metadata', '/test_data', '/test_ids', '/test_labels', '/train_data', '/train_labels']\n",
      "Training images: 85375\n",
      "Testing images: 13619\n",
      "Training image mean = 15.747216671459945 and std = 19.44407238183732\n",
      "Testing image mean = 15.739041926556125 and std = 19.47083198216387\n",
      "(85375, 7168)\n",
      "(13619, 7168)\n",
      "(85375,)\n",
      "(13619,)\n",
      "(98994, 7168)\n",
      "(98994,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awoloshu\\Documents\\pytorch36\\lib\\site-packages\\tables\\leaf.py:353: RuntimeWarning: overflow encountered in long_scalars\n",
      "  expected_mb = (expectedrows * rowsize) // MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TrainingNum  TestingNum  TrainingMean  TrainingStd\n",
      "0        98994           0     15.746092    19.447756\n",
      "FIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Successfully created C:/Users/awoloshu/Desktop/datasets/f33f44combined_noCNT/3d_all/pruned_train_test/f33f44combined_noCNT_3d_all_prune_bad_labels1_combined.h5\n",
      "===============\n",
      "4 keys in this file: ['/Metadata', '/test_ids', '/train_data', '/train_labels']\n"
     ]
    }
   ],
   "source": [
    "filename = config['data_loader']['args']['hdf5_path']\n",
    "path = filename.split('.')\n",
    "path = path[0] + \"_combined.h5\"\n",
    "print(\"NEW FILE \" + path)\n",
    "store = pd.HDFStore(path)\n",
    "with pd.HDFStore(filename) as f:\n",
    "        print()\n",
    "        print(\"Successfully created \" + path)\n",
    "        print(\"===============\")\n",
    "        keys = list(f.keys())\n",
    "        print(\"{0} keys in this file: {1}\".format(len(keys), keys))\n",
    "        \n",
    "        num_images_train = f['Metadata']['TrainingNum'][0]\n",
    "        num_images_test = f['Metadata']['TestingNum'][0]\n",
    "        mean = f['Metadata']['TrainingMean'][0]\n",
    "        std = f['Metadata']['TrainingStd'][0]\n",
    "        '''\n",
    "        num_images_train = len(f['train_data'])\n",
    "        num_images_test = len(f['test_data'])\n",
    "        mean = np.mean(f['train_data'].to_numpy())\n",
    "        std = np.std(f['train_data'].to_numpy())\n",
    "        '''\n",
    "        mean_t = np.mean(f['test_data'].to_numpy())\n",
    "        std_t = np.std(f['test_data'].to_numpy())\n",
    "        \n",
    "        print(\"Training images: \" + str(num_images_train))\n",
    "        print(\"Testing images: \" + str(num_images_test))\n",
    "        print(\"Training image mean = \" + str(mean) + \" and std = \" + str(std))\n",
    "        print(\"Testing image mean = \" + str(mean_t) + \" and std = \" + str(std_t))\n",
    "        \n",
    "        train_data = f['train_data'].to_numpy()\n",
    "        train_label = f['train_labels'].to_numpy()\n",
    "        test_data = f['test_data'].to_numpy()\n",
    "        test_label = f['test_labels'].to_numpy()\n",
    "        \n",
    "        train_label = train_label.squeeze()\n",
    "        test_label = test_label.squeeze()\n",
    "        \n",
    "        print(train_data.shape)\n",
    "        print(test_data.shape)\n",
    "        print(train_label.shape)\n",
    "        print(test_label.shape)\n",
    "        combined_data = np.concatenate((train_data, test_data), axis = 0)\n",
    "        combined_label = np.concatenate((train_label, test_label), axis = 0)\n",
    "        \n",
    "                \n",
    "        print(combined_data.shape)\n",
    "        print(combined_label.shape)\n",
    "        \n",
    "        \n",
    "        store.append('train_data', pd.DataFrame(combined_data.astype(np.int64)))\n",
    "        store.append('train_labels', pd.DataFrame(combined_label.astype(np.int64)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        metadata = pd.DataFrame({'TrainingNum': len(combined_data), 'TestingNum': 0, \\\n",
    "                'TrainingMean': np.mean(combined_data), 'TrainingStd': np.std(combined_data)}, index=[0])      \n",
    "        store.append('Metadata', metadata)\n",
    "        store.append('test_ids', f['test_ids'])\n",
    "        print(metadata)\n",
    "        \n",
    "        del train_data, test_data\n",
    "        print(\"FIN\")\n",
    "store.close() \n",
    "\n",
    "with pd.HDFStore(path) as f:\n",
    "        print('\\n\\n\\n')\n",
    "        print(\"Successfully created \" + path)\n",
    "        print(\"===============\")\n",
    "        keys = list(f.keys())\n",
    "        print(\"{0} keys in this file: {1}\".format(len(keys), keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
